{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Main function.\n",
    "# Extracting streaming data from Twitter, pre-processing, and loading into MySQL\n",
    "import credentials # Import api/access_token keys from credentials.py\n",
    "import settings # Import related setting constants from pogdb.py \n",
    "\n",
    "import re\n",
    "import tweepy\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import api/access_token keys from credentials.py\n",
    "import credentials\n",
    "auth  = tweepy.OAuthHandler(credentials.API_KEY, \\\n",
    "                            credentials.API_SECRET_KEY)\n",
    "auth.set_access_token(credentials.ACCESS_TOKEN,  \\\n",
    "                      credentials.ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The fuctions are used to clean the tweets\n",
    "def clean_tweet(self, tweet): \n",
    "    ''' \n",
    "    Use sumple regex statemnents to clean tweet text by removing links and special characters\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) \\\n",
    "                                |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "def deEmojify(text):\n",
    "    '''\n",
    "    Strip all non-ASCII characters to remove emoji characters\n",
    "    '''\n",
    "    if text:\n",
    "        return text.encode('ascii', 'ignore').decode('ascii')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    },
    {
     "ename": "DuplicateTable",
     "evalue": "relation \"nairobitweets\" already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateTable\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e94cfdbe520f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"table exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     if mycursor.fetchone()[0] != 1:\"\"\"\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmycursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE TABLE {} ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTABLE_ATTRIBUTES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Table does not exist so it has been created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdbconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateTable\u001b[0m: relation \"nairobitweets\" already exists\n"
     ]
    }
   ],
   "source": [
    "#This connnects to the database, checks if a table {\"Tablename\"} exits, if not creates one and closes the connection\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "dbconn = psycopg2.connect(\"host=ec2-54-81-37-115.compute-1.amazonaws.com dbname=d58g5m66umb113 user=eigxqdhsrlaffv password=b1495696080d3ad38656b3e2973e25cd8890a1570a7639abdf756cbbd793c8f1\")\n",
    "if dbconn:\n",
    "    print(\"Connected\")\n",
    "    '''\n",
    "    Check if this table exits. If not, then create a new one.\n",
    "    '''\n",
    "    mycursor = dbconn.cursor()\n",
    "    \"\"\"mycursor.execute(\n",
    "    SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = '{0}'.format(settings.TABLE_NAME))\n",
    "    print(\"table exists\")\n",
    "    if mycursor.fetchone()[0] != 1:\"\"\"\n",
    "    mycursor.execute(\"CREATE TABLE {} ({})\".format(settings.TABLE_NAME, settings.TABLE_ATTRIBUTES))\n",
    "    print(\"Table does not exist so it has been created\")\n",
    "    dbconn.commit()\n",
    "    mycursor.close()\n",
    "else:\n",
    "    print('Not connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a listener to watch for our data\n",
    "#has two functions\n",
    "#on_status it to check for tweets\n",
    "#on_error is to stop tweet checking incase a limit is reached\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    '''\n",
    "    Tweets are known as “status updates”. So the Status class in tweepy has properties describing the tweet.\n",
    "    https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html\n",
    "    '''\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        '''\n",
    "        Extract info from tweets\n",
    "        '''\n",
    "        \n",
    "        if status.retweeted:\n",
    "            # Avoid retweeted info, and only original tweets will be received\n",
    "            return True\n",
    "        # Extract attributes from each tweet\n",
    "        id_str = status.id_str\n",
    "        created_at = status.created_at\n",
    "        text = deEmojify(status.text)    # Pre-processing the text  \n",
    "        sentiment = TextBlob(text).sentiment\n",
    "        polarity = sentiment.polarity\n",
    "        subjectivity = sentiment.subjectivity\n",
    "        \n",
    "        user_created_at = status.user.created_at\n",
    "        user_location = deEmojify(status.user.location)\n",
    "        user_description = deEmojify(status.user.description)\n",
    "        user_followers_count =status.user.followers_count\n",
    "        longitude = None\n",
    "        latitude = None\n",
    "        if status.coordinates:\n",
    "            longitude = status.coordinates['coordinates'][0]\n",
    "            latitude = status.coordinates['coordinates'][1]\n",
    "            print(longitude)\n",
    "            print(latitude)\n",
    "        retweet_count = status.retweet_count\n",
    "        favorite_count = status.favorite_count\n",
    "        \n",
    "        print(status.text)\n",
    "        print(\"Long: {}, Lati: {}\".format(longitude, latitude))\n",
    "        \n",
    "        # Store all data in MySQL\n",
    "        if dbconn:\n",
    "            mycursor = dbconn.cursor()\n",
    "            sql = \"INSERT INTO {} (id_str,created_at,text,polarity,\\\n",
    "                subjectivity, user_created_at, user_location,\\\n",
    "                user_description, user_followers_count, longitude,\\\n",
    "                latitude, retweet_count, favorite_count) VALUES \\\n",
    "                (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\".format(settings.TABLE_NAME)\n",
    "            val = (id_str, created_at, text, polarity, subjectivity,\\\n",
    "                 user_created_at, user_location, user_description, user_followers_count, longitude, latitude, retweet_count, favorite_count)\n",
    "            mycursor.execute(sql, val)\n",
    "            dbconn.commit()\n",
    "            mycursor.close()\n",
    "    \n",
    "    \n",
    "    def on_error(self, status_code):\n",
    "        '''\n",
    "        Since Twitter API has rate limits, stop srcraping data as it exceed to the thresold.\n",
    "        '''\n",
    "        if status_code == 420:\n",
    "            # return False to disconnect the stream\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This calls the class myStreamListener thereby witing into the database\n",
    "'''places = api.search(query=\"Nairobi\", granularity=\"city\")\n",
    "place_id = places[0].id\n",
    "public_tweets = api.search(q=\"place:%s\" %place_id)\n",
    "'''\n",
    "GEOBOX_WORLD = [-180,-90,180,90]\n",
    "GEOBOX_NAIROBI = [-1.1597918307560573,36.665974517587834,-1.3891756881977984,37.106463945682584]\n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener = myStreamListener)\n",
    "myStream.filter(locations=GEOBOX_NAIROBI)\n",
    "                            \n",
    "# Close the postgres connection as it finished\n",
    "# However, this won't be reached as the stream listener won't stop automatically\n",
    "# Press STOP button to finish the process.\n",
    "dbconn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is used to read data from the database\n",
    "import psycopg2\n",
    "try:\n",
    "    connection = psycopg2.connect(user=\"eigxqdhsrlaffv\",\n",
    "                                  password=\"b1495696080d3ad38656b3e2973e25cd8890a1570a7639abdf756cbbd793c8f1\",\n",
    "                                  host=\"ec2-54-81-37-115.compute-1.amazonaws.com\",\n",
    "                                  database=\"d58g5m66umb113\")\n",
    "    cursor = connection.cursor()\n",
    "    postgreSQL_select_Query = \"select * from nairobitweets\"\n",
    "\n",
    "    cursor.execute(postgreSQL_select_Query)\n",
    "    print(\"Selecting rows from tweets table using cursor.fetchall\")\n",
    "    tweet_records = cursor.fetchall() \n",
    "   \n",
    "    print(\"Print each row and it's columns values\")\n",
    "    for row in tweet_records:\n",
    "        print(\"Id = \", row[0], )\n",
    "        print(\"created_at = \", row[1], )\n",
    "        print(\"text  = \", row[2], )\n",
    "        print(\"polarity = \", row[3], )\n",
    "        print(\"subjectivity = \", row[4], \"\\n\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error :\n",
    "    print (\"Error while fetching data from PostgreSQL\", error)\n",
    "\n",
    "finally:\n",
    "    #closing database connection.\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed\").close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\copy (SELECT * FROM tweets) to 'C:\\tmp\\persons_client.csv' with csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
