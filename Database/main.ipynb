{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Main function.\n",
    "# Extracting streaming data from Twitter, pre-processing, and loading into MySQL\n",
    "import credentials # Import api/access_token keys from credentials.py\n",
    "import settings # Import related setting constants from pogdb.py \n",
    "\n",
    "import re\n",
    "import tweepy\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import api/access_token keys from credentials.py\n",
    "import credentials\n",
    "auth  = tweepy.OAuthHandler(credentials.API_KEY, \\\n",
    "                            credentials.API_SECRET_KEY)\n",
    "auth.set_access_token(credentials.ACCESS_TOKEN,  \\\n",
    "                      credentials.ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The fuctions are used to clean the tweets\n",
    "def clean_tweet(self, tweet): \n",
    "    ''' \n",
    "    Use sumple regex statemnents to clean tweet text by removing links and special characters\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) \\\n",
    "                                |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "def deEmojify(text):\n",
    "    '''\n",
    "    Strip all non-ASCII characters to remove emoji characters\n",
    "    '''\n",
    "    if text:\n",
    "        return text.encode('ascii', 'ignore').decode('ascii')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n",
      "Table already exists.\n"
     ]
    }
   ],
   "source": [
    "#This connnects to the database, checks if a table {\"Tablename\"} exits, if not creates one and closes the connection\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "dbconn = psycopg2.connect(\"host=ec2-52-207-25-133.compute-1.amazonaws.com dbname=d8e9au4m77k9b1 user=twvlbubsgabvpj password=53cf31e1928ac9f0ec3ec5554a92bfa96ddb693b7bb3b31df2bbf3784cc66f6a\")\n",
    "if dbconn:\n",
    "    print(\"Connected\")\n",
    "    '''\n",
    "    Check if this table exits. If not, then create a new one.\n",
    "    '''\n",
    "    mycursor = dbconn.cursor()\n",
    "    \"\"\"mycursor.execute(\n",
    "    SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = '{0}'.format(settings.TABLE_NAME))\n",
    "    print(\"table exists\")\"\"\"\n",
    "    mycursor.execute(\"select * from information_schema.tables where table_name=%s\", ('nairobitweets',))\n",
    "    if bool(mycursor.rowcount) == False:\n",
    "    \n",
    "        mycursor.execute(\"CREATE TABLE {} ({})\".format(settings.TABLE_NAME, settings.TABLE_ATTRIBUTES))\n",
    "        print(\"Table does not exist so it has been created\")\n",
    "        dbconn.commit()\n",
    "        mycursor.close()\n",
    "    else:\n",
    "        print(\"Table already exists.\")\n",
    "        dbconn.commit()\n",
    "        mycursor.close()\n",
    "else:\n",
    "    print('Not connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a listener to watch for our data\n",
    "#has two functions\n",
    "#on_status it to check for tweets\n",
    "#on_error is to stop tweet checking incase a limit is reached\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    '''\n",
    "    Tweets are known as “status updates”. So the Status class in tweepy has properties describing the tweet.\n",
    "    https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html\n",
    "    '''\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        '''\n",
    "        Extract info from tweets\n",
    "        '''\n",
    "        \n",
    "        if status.retweeted:\n",
    "            # Avoid retweeted info, and only original tweets will be received\n",
    "            return True\n",
    "        # Extract attributes from each tweet\n",
    "        id_str = status.id_str\n",
    "        created_at = status.created_at\n",
    "        text = deEmojify(status.text)    # Pre-processing the text  \n",
    "        sentiment = TextBlob(text).sentiment\n",
    "        polarity = sentiment.polarity\n",
    "        subjectivity = sentiment.subjectivity\n",
    "        \n",
    "        user_created_at = status.user.created_at\n",
    "        user_location = deEmojify(status.user.location)\n",
    "        user_description = deEmojify(status.user.description)\n",
    "        user_followers_count =status.user.followers_count\n",
    "        longitude = None\n",
    "        latitude = None\n",
    "        if status.coordinates:\n",
    "            longitude = status.coordinates['coordinates'][0]\n",
    "            latitude = status.coordinates['coordinates'][1]\n",
    "            print(longitude)\n",
    "            print(latitude)\n",
    "        retweet_count = status.retweet_count\n",
    "        favorite_count = status.favorite_count\n",
    "        \n",
    "        print(status.text)\n",
    "        print(\"Long: {}, Lati: {}\".format(longitude, latitude))\n",
    "        \n",
    "        # Store all data in MySQL\n",
    "        if dbconn:\n",
    "            dbcursor = dbconn.cursor()\n",
    "            sql = \"INSERT INTO {} (id_str,created_at,text,polarity,\\\n",
    "                subjectivity, user_created_at, user_location,\\\n",
    "                user_description, user_followers_count, longitude,\\\n",
    "                latitude, retweet_count, favorite_count) VALUES \\\n",
    "                (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\".format(settings.TABLE_NAME)\n",
    "            val = (id_str, created_at, text, polarity, subjectivity,\\\n",
    "                 user_created_at, user_location, user_description, user_followers_count, longitude, latitude, retweet_count, favorite_count)\n",
    "            dbcursor.execute(sql, val)\n",
    "            dbconn.commit()\n",
    "    \n",
    "    def on_error(self, status_code):\n",
    "        '''\n",
    "        Since Twitter API has rate limits, stop scraping data as it exceed to the thresold.\n",
    "        '''\n",
    "        if status_code == 420:\n",
    "            # return False to disconnect the stream\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@rodah_ And I- https://t.co/53eSgZNioR\n",
      "Long: None, Lati: None\n",
      "@Jerriesam Thanks fam!!!\n",
      "Long: None, Lati: None\n",
      "interview in Nairobi.Stella travelled to Japan,from where he kept Mwamburi well apprised of her progress via mail.B… https://t.co/6sv3wbOGht\n",
      "Long: None, Lati: None\n",
      "@kinglastie1 @OleItumbi @bm_bashir @StateHouseKenya @JunetMohamed @RailaOdinga @Railajunior @kipmurkomen… https://t.co/chjQzArJI7\n",
      "Long: None, Lati: None\n"
     ]
    }
   ],
   "source": [
    "#This calls the class myStreamListener thereby witing into the database\n",
    "'''places = api.search(query=\"Nairobi\", granularity=\"city\")\n",
    "place_id = places[0].id\n",
    "public_tweets = api.search(q=\"place:%s\" %place_id)\n",
    "'''\n",
    "GEOBOX_WORLD = [-180,-90,180,90]\n",
    "GEOBOX_NAIROBI = [36.542329,-1.538666,37.186403,-1.052647]\n",
    "while True:\n",
    "    try:\n",
    "        myStreamListener = MyStreamListener()\n",
    "        myStream = tweepy.Stream(auth = api.auth, listener = myStreamListener)\n",
    "        myStream.filter(languages=[\"en\"], locations=GEOBOX_NAIROBI)\n",
    "        dbconn.commit()\n",
    "        # Close the postgres connection as it finished\n",
    "        # However, this won't be reached as the stream listener won't stop automatically\n",
    "        # Press STOP button to finish the process.\n",
    "    except:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will be adding the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
